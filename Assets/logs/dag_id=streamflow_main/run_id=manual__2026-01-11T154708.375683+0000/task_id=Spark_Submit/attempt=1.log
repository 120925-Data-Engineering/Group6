[2026-01-11T15:48:17.670+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: streamflow_main.Spark_Submit manual__2026-01-11T15:47:08.375683+00:00 [queued]>
[2026-01-11T15:48:17.681+0000] {taskinstance.py:1956} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: streamflow_main.Spark_Submit manual__2026-01-11T15:47:08.375683+00:00 [queued]>
[2026-01-11T15:48:17.682+0000] {taskinstance.py:2170} INFO - Starting attempt 1 of 1
[2026-01-11T15:48:17.701+0000] {taskinstance.py:2191} INFO - Executing <Task(BashOperator): Spark_Submit> on 2026-01-11 15:47:08.375683+00:00
[2026-01-11T15:48:17.706+0000] {standard_task_runner.py:60} INFO - Started process 342 to run task
[2026-01-11T15:48:17.710+0000] {standard_task_runner.py:87} INFO - Running: ['***', 'tasks', 'run', 'streamflow_main', 'Spark_Submit', 'manual__2026-01-11T15:47:08.375683+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/dag_streamflow.py', '--cfg-path', '/tmp/tmprn4_e4yi']
[2026-01-11T15:48:17.713+0000] {standard_task_runner.py:88} INFO - Job 4: Subtask Spark_Submit
[2026-01-11T15:48:17.772+0000] {task_command.py:423} INFO - Running <TaskInstance: streamflow_main.Spark_Submit manual__2026-01-11T15:47:08.375683+00:00 [running]> on host 139c0fac8954
[2026-01-11T15:48:17.868+0000] {taskinstance.py:2480} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='student' AIRFLOW_CTX_DAG_ID='streamflow_main' AIRFLOW_CTX_TASK_ID='Spark_Submit' AIRFLOW_CTX_EXECUTION_DATE='2026-01-11T15:47:08.375683+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2026-01-11T15:47:08.375683+00:00'
[2026-01-11T15:48:17.869+0000] {subprocess.py:63} INFO - Tmp dir root location: /tmp
[2026-01-11T15:48:17.871+0000] {subprocess.py:75} INFO - Running command: ['/usr/bin/bash', '-c', '\n            spark-submit                 --master spark://spark-master:7077                 /opt/spark-jobs/etl_job.py\n        ']
[2026-01-11T15:48:17.881+0000] {subprocess.py:86} INFO - Output:
[2026-01-11T15:48:17.892+0000] {subprocess.py:93} INFO - /opt/spark/bin/load-spark-env.sh: line 68: ps: command not found
[2026-01-11T15:48:21.580+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SparkContext: Running Spark version 3.5.0
[2026-01-11T15:48:21.582+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SparkContext: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2026-01-11T15:48:21.583+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SparkContext: Java version 17.0.17
[2026-01-11T15:48:21.669+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
[2026-01-11T15:48:21.822+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO ResourceUtils: ==============================================================
[2026-01-11T15:48:21.823+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO ResourceUtils: No custom resources configured for spark.driver.
[2026-01-11T15:48:21.824+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO ResourceUtils: ==============================================================
[2026-01-11T15:48:21.825+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SparkContext: Submitted application: ETL_job
[2026-01-11T15:48:21.854+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
[2026-01-11T15:48:21.864+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO ResourceProfile: Limiting resource is cpu
[2026-01-11T15:48:21.865+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO ResourceProfileManager: Added ResourceProfile id: 0
[2026-01-11T15:48:21.946+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SecurityManager: Changing view acls to: root
[2026-01-11T15:48:21.947+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SecurityManager: Changing modify acls to: root
[2026-01-11T15:48:21.948+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SecurityManager: Changing view acls groups to:
[2026-01-11T15:48:21.949+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SecurityManager: Changing modify acls groups to:
[2026-01-11T15:48:21.950+0000] {subprocess.py:93} INFO - 26/01/11 15:48:21 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
[2026-01-11T15:48:22.301+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Utils: Successfully started service 'sparkDriver' on port 41717.
[2026-01-11T15:48:22.359+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO SparkEnv: Registering MapOutputTracker
[2026-01-11T15:48:22.427+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO SparkEnv: Registering BlockManagerMaster
[2026-01-11T15:48:22.453+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
[2026-01-11T15:48:22.454+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
[2026-01-11T15:48:22.462+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
[2026-01-11T15:48:22.505+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-d6c07953-5b77-43d5-91e1-686f3c8331f6
[2026-01-11T15:48:22.523+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO MemoryStore: MemoryStore started with capacity 434.4 MiB
[2026-01-11T15:48:22.547+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO SparkEnv: Registering OutputCommitCoordinator
[2026-01-11T15:48:22.741+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
[2026-01-11T15:48:22.845+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Utils: Successfully started service 'SparkUI' on port 4040.
[2026-01-11T15:48:22.979+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Executor: Starting executor ID driver on host 139c0fac8954
[2026-01-11T15:48:22.980+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Executor: OS info Linux, 5.15.167.4-microsoft-standard-WSL2, amd64
[2026-01-11T15:48:22.981+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Executor: Java version 17.0.17
[2026-01-11T15:48:22.987+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
[2026-01-11T15:48:22.991+0000] {subprocess.py:93} INFO - 26/01/11 15:48:22 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@272584ff for default.
[2026-01-11T15:48:23.010+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 41559.
[2026-01-11T15:48:23.011+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO NettyBlockTransferService: Server created on 139c0fac8954:41559
[2026-01-11T15:48:23.013+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
[2026-01-11T15:48:23.019+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 139c0fac8954, 41559, None)
[2026-01-11T15:48:23.023+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO BlockManagerMasterEndpoint: Registering block manager 139c0fac8954:41559 with 434.4 MiB RAM, BlockManagerId(driver, 139c0fac8954, 41559, None)
[2026-01-11T15:48:23.024+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 139c0fac8954, 41559, None)
[2026-01-11T15:48:23.026+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, 139c0fac8954, 41559, None)
[2026-01-11T15:48:23.671+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir.
[2026-01-11T15:48:23.678+0000] {subprocess.py:93} INFO - 26/01/11 15:48:23 INFO SharedState: Warehouse path is 'file:/tmp/***tmpyd7b5w_n/spark-warehouse'.
[2026-01-11T15:48:24.904+0000] {subprocess.py:93} INFO - 26/01/11 15:48:24 INFO InMemoryFileIndex: It took 68 ms to list leaf files for 1 paths.
[2026-01-11T15:48:25.020+0000] {subprocess.py:93} INFO - 26/01/11 15:48:25 INFO InMemoryFileIndex: It took 18 ms to list leaf files for 1 paths.
[2026-01-11T15:48:28.372+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO FileSourceStrategy: Pushed Filters:
[2026-01-11T15:48:28.382+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO FileSourceStrategy: Post-Scan Filters:
[2026-01-11T15:48:28.616+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 199.2 KiB, free 434.2 MiB)
[2026-01-11T15:48:28.685+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 434.2 MiB)
[2026-01-11T15:48:28.689+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on 139c0fac8954:41559 (size: 34.2 KiB, free: 434.4 MiB)
[2026-01-11T15:48:28.693+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO SparkContext: Created broadcast 0 from json at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:28.703+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2026-01-11T15:48:28.862+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:28.879+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO DAGScheduler: Got job 0 (json at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2026-01-11T15:48:28.880+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO DAGScheduler: Final stage: ResultStage 0 (json at NativeMethodAccessorImpl.java:0)
[2026-01-11T15:48:28.881+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO DAGScheduler: Parents of final stage: List()
[2026-01-11T15:48:28.882+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO DAGScheduler: Missing parents: List()
[2026-01-11T15:48:28.885+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[2026-01-11T15:48:28.967+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.0 KiB, free 434.2 MiB)
[2026-01-11T15:48:28.974+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 434.1 MiB)
[2026-01-11T15:48:28.975+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO BlockManagerInfo: Added broadcast_1_piece0 in memory on 139c0fac8954:41559 (size: 7.5 KiB, free: 434.4 MiB)
[2026-01-11T15:48:28.976+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1580
[2026-01-11T15:48:28.989+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2026-01-11T15:48:28.991+0000] {subprocess.py:93} INFO - 26/01/11 15:48:28 INFO TaskSchedulerImpl: Adding task set 0.0 with 2 tasks resource profile 0
[2026-01-11T15:48:29.030+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (139c0fac8954, executor driver, partition 0, PROCESS_LOCAL, 8251 bytes)
[2026-01-11T15:48:29.034+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (139c0fac8954, executor driver, partition 1, PROCESS_LOCAL, 8251 bytes)
[2026-01-11T15:48:29.044+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
[2026-01-11T15:48:29.045+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
[2026-01-11T15:48:29.145+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/transaction_events_1768146431.4381304.json, range: 0-4194304, partition values: [empty row]
[2026-01-11T15:48:29.146+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/transaction_events_1768146431.4381304.json, range: 4194304-5332234, partition values: [empty row]
[2026-01-11T15:48:29.401+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO CodeGenerator: Code generated in 219.441442 ms
[2026-01-11T15:48:29.662+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 2997 bytes result sent to driver
[2026-01-11T15:48:29.673+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 638 ms on 139c0fac8954 (executor driver) (1/2)
[2026-01-11T15:48:29.816+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 2997 bytes result sent to driver
[2026-01-11T15:48:29.820+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 801 ms on 139c0fac8954 (executor driver) (2/2)
[2026-01-11T15:48:29.821+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
[2026-01-11T15:48:29.821+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO DAGScheduler: ResultStage 0 (json at NativeMethodAccessorImpl.java:0) finished in 0.923 s
[2026-01-11T15:48:29.823+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
[2026-01-11T15:48:29.824+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
[2026-01-11T15:48:29.826+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO DAGScheduler: Job 0 finished: json at NativeMethodAccessorImpl.java:0, took 0.963213 s
[2026-01-11T15:48:29.943+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO InMemoryFileIndex: It took 12 ms to list leaf files for 1 paths.
[2026-01-11T15:48:29.965+0000] {subprocess.py:93} INFO - 26/01/11 15:48:29 INFO InMemoryFileIndex: It took 8 ms to list leaf files for 1 paths.
[2026-01-11T15:48:30.010+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceStrategy: Pushed Filters:
[2026-01-11T15:48:30.011+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceStrategy: Post-Scan Filters:
[2026-01-11T15:48:30.015+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO MemoryStore: Block broadcast_2 stored as values in memory (estimated size 199.2 KiB, free 434.0 MiB)
[2026-01-11T15:48:30.025+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)
[2026-01-11T15:48:30.026+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO BlockManagerInfo: Added broadcast_2_piece0 in memory on 139c0fac8954:41559 (size: 34.2 KiB, free: 434.3 MiB)
[2026-01-11T15:48:30.028+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO SparkContext: Created broadcast 2 from json at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:30.030+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2026-01-11T15:48:30.043+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO SparkContext: Starting job: json at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:30.045+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Got job 1 (json at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2026-01-11T15:48:30.046+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Final stage: ResultStage 1 (json at NativeMethodAccessorImpl.java:0)
[2026-01-11T15:48:30.046+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Parents of final stage: List()
[2026-01-11T15:48:30.047+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Missing parents: List()
[2026-01-11T15:48:30.048+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0), which has no missing parents
[2026-01-11T15:48:30.049+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.0 KiB, free 433.9 MiB)
[2026-01-11T15:48:30.051+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.5 KiB, free 433.9 MiB)
[2026-01-11T15:48:30.051+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO BlockManagerInfo: Added broadcast_3_piece0 in memory on 139c0fac8954:41559 (size: 7.5 KiB, free: 434.3 MiB)
[2026-01-11T15:48:30.052+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1580
[2026-01-11T15:48:30.053+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at json at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2026-01-11T15:48:30.054+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO TaskSchedulerImpl: Adding task set 1.0 with 1 tasks resource profile 0
[2026-01-11T15:48:30.055+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO TaskSetManager: Starting task 0.0 in stage 1.0 (TID 2) (139c0fac8954, executor driver, partition 0, PROCESS_LOCAL, 8244 bytes)
[2026-01-11T15:48:30.055+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO Executor: Running task 0.0 in stage 1.0 (TID 2)
[2026-01-11T15:48:30.062+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/user_events_1768146431.4385798.json, range: 0-1917087, partition values: [empty row]
[2026-01-11T15:48:30.263+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO Executor: Finished task 0.0 in stage 1.0 (TID 2). 2358 bytes result sent to driver
[2026-01-11T15:48:30.265+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO TaskSetManager: Finished task 0.0 in stage 1.0 (TID 2) in 211 ms on 139c0fac8954 (executor driver) (1/1)
[2026-01-11T15:48:30.266+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO TaskSchedulerImpl: Removed TaskSet 1.0, whose tasks have all completed, from pool
[2026-01-11T15:48:30.266+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: ResultStage 1 (json at NativeMethodAccessorImpl.java:0) finished in 0.219 s
[2026-01-11T15:48:30.267+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Job 1 is finished. Cancelling potential speculative or zombie tasks for this job
[2026-01-11T15:48:30.268+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO TaskSchedulerImpl: Killing all running tasks in stage 1: Stage finished
[2026-01-11T15:48:30.268+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO DAGScheduler: Job 1 finished: json at NativeMethodAccessorImpl.java:0, took 0.224229 s
[2026-01-11T15:48:30.484+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO BlockManagerInfo: Removed broadcast_2_piece0 on 139c0fac8954:41559 in memory (size: 34.2 KiB, free: 434.4 MiB)
[2026-01-11T15:48:30.493+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO BlockManagerInfo: Removed broadcast_1_piece0 on 139c0fac8954:41559 in memory (size: 7.5 KiB, free: 434.4 MiB)
[2026-01-11T15:48:30.499+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO BlockManagerInfo: Removed broadcast_3_piece0 on 139c0fac8954:41559 in memory (size: 7.5 KiB, free: 434.4 MiB)
[2026-01-11T15:48:30.728+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(products),IsNotNull(user_id)
[2026-01-11T15:48:30.730+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceStrategy: Post-Scan Filters: (size(products#12, true) > 0),isnotnull(products#12),isnotnull(user_id#21)
[2026-01-11T15:48:30.734+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceStrategy: Pushed Filters: IsNotNull(user_id),IsNotNull(product_id)
[2026-01-11T15:48:30.735+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(user_id#58),isnotnull(product_id#53)
[2026-01-11T15:48:30.821+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
[2026-01-11T15:48:30.954+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO CodeGenerator: Code generated in 37.765302 ms
[2026-01-11T15:48:30.958+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO MemoryStore: Block broadcast_4 stored as values in memory (estimated size 199.1 KiB, free 434.0 MiB)
[2026-01-11T15:48:30.967+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 433.9 MiB)
[2026-01-11T15:48:30.968+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO BlockManagerInfo: Added broadcast_4_piece0 in memory on 139c0fac8954:41559 (size: 34.2 KiB, free: 434.3 MiB)
[2026-01-11T15:48:30.969+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO SparkContext: Created broadcast 4 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2026-01-11T15:48:30.973+0000] {subprocess.py:93} INFO - 26/01/11 15:48:30 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2026-01-11T15:48:31.003+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2026-01-11T15:48:31.005+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Got job 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2026-01-11T15:48:31.006+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Final stage: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2026-01-11T15:48:31.006+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Parents of final stage: List()
[2026-01-11T15:48:31.007+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Missing parents: List()
[2026-01-11T15:48:31.008+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2026-01-11T15:48:31.012+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_5 stored as values in memory (estimated size 20.0 KiB, free 433.9 MiB)
[2026-01-11T15:48:31.014+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 8.3 KiB, free 433.9 MiB)
[2026-01-11T15:48:31.015+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO BlockManagerInfo: Added broadcast_5_piece0 in memory on 139c0fac8954:41559 (size: 8.3 KiB, free: 434.3 MiB)
[2026-01-11T15:48:31.016+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1580
[2026-01-11T15:48:31.017+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2026-01-11T15:48:31.017+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSchedulerImpl: Adding task set 2.0 with 1 tasks resource profile 0
[2026-01-11T15:48:31.018+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSetManager: Starting task 0.0 in stage 2.0 (TID 3) (139c0fac8954, executor driver, partition 0, PROCESS_LOCAL, 8244 bytes)
[2026-01-11T15:48:31.019+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO Executor: Running task 0.0 in stage 2.0 (TID 3)
[2026-01-11T15:48:31.058+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 22.845414 ms
[2026-01-11T15:48:31.062+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/user_events_1768146431.4385798.json, range: 0-1917087, partition values: [empty row]
[2026-01-11T15:48:31.094+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 19.125664 ms
[2026-01-11T15:48:31.127+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 6.159773 ms
[2026-01-11T15:48:31.135+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 5.55543 ms
[2026-01-11T15:48:31.351+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO Executor: Finished task 0.0 in stage 2.0 (TID 3). 246655 bytes result sent to driver
[2026-01-11T15:48:31.353+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSetManager: Finished task 0.0 in stage 2.0 (TID 3) in 335 ms on 139c0fac8954 (executor driver) (1/1)
[2026-01-11T15:48:31.354+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSchedulerImpl: Removed TaskSet 2.0, whose tasks have all completed, from pool
[2026-01-11T15:48:31.354+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: ResultStage 2 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.345 s
[2026-01-11T15:48:31.355+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
[2026-01-11T15:48:31.355+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 2: Stage finished
[2026-01-11T15:48:31.356+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Job 2 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.350926 s
[2026-01-11T15:48:31.374+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 6.769434 ms
[2026-01-11T15:48:31.387+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_6 stored as values in memory (estimated size 1088.0 KiB, free 432.9 MiB)
[2026-01-11T15:48:31.398+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 266.5 KiB, free 432.6 MiB)
[2026-01-11T15:48:31.399+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO BlockManagerInfo: Added broadcast_6_piece0 in memory on 139c0fac8954:41559 (size: 266.5 KiB, free: 434.1 MiB)
[2026-01-11T15:48:31.400+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO SparkContext: Created broadcast 6 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2026-01-11T15:48:31.437+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO FileSourceStrategy: Pushed Filters: IsNotNull(products),IsNotNull(user_id)
[2026-01-11T15:48:31.438+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO FileSourceStrategy: Post-Scan Filters: (size(products#12, true) > 0),isnotnull(products#12),isnotnull(user_id#21)
[2026-01-11T15:48:31.627+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 64.943597 ms
[2026-01-11T15:48:31.630+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_7 stored as values in memory (estimated size 199.1 KiB, free 432.4 MiB)
[2026-01-11T15:48:31.643+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO BlockManagerInfo: Removed broadcast_5_piece0 on 139c0fac8954:41559 in memory (size: 8.3 KiB, free: 434.1 MiB)
[2026-01-11T15:48:31.645+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 432.4 MiB)
[2026-01-11T15:48:31.646+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO BlockManagerInfo: Added broadcast_7_piece0 in memory on 139c0fac8954:41559 (size: 34.2 KiB, free: 434.0 MiB)
[2026-01-11T15:48:31.647+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO SparkContext: Created broadcast 7 from showString at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:31.649+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2026-01-11T15:48:31.664+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:31.666+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions
[2026-01-11T15:48:31.666+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)
[2026-01-11T15:48:31.667+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Parents of final stage: List()
[2026-01-11T15:48:31.668+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Missing parents: List()
[2026-01-11T15:48:31.668+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents
[2026-01-11T15:48:31.669+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_8 stored as values in memory (estimated size 46.2 KiB, free 432.3 MiB)
[2026-01-11T15:48:31.675+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 15.4 KiB, free 432.3 MiB)
[2026-01-11T15:48:31.676+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO BlockManagerInfo: Added broadcast_8_piece0 in memory on 139c0fac8954:41559 (size: 15.4 KiB, free: 434.0 MiB)
[2026-01-11T15:48:31.678+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO SparkContext: Created broadcast 8 from broadcast at DAGScheduler.scala:1580
[2026-01-11T15:48:31.679+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))
[2026-01-11T15:48:31.679+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSchedulerImpl: Adding task set 3.0 with 1 tasks resource profile 0
[2026-01-11T15:48:31.681+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSetManager: Starting task 0.0 in stage 3.0 (TID 4) (139c0fac8954, executor driver, partition 0, PROCESS_LOCAL, 8251 bytes)
[2026-01-11T15:48:31.682+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO Executor: Running task 0.0 in stage 3.0 (TID 4)
[2026-01-11T15:48:31.734+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 46.736517 ms
[2026-01-11T15:48:31.738+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/transaction_events_1768146431.4381304.json, range: 0-4194304, partition values: [empty row]
[2026-01-11T15:48:31.766+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 17.599456 ms
[2026-01-11T15:48:31.774+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 5.219801 ms
[2026-01-11T15:48:31.780+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 3.854682 ms
[2026-01-11T15:48:31.842+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO Executor: Finished task 0.0 in stage 3.0 (TID 4). 13482 bytes result sent to driver
[2026-01-11T15:48:31.843+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSetManager: Finished task 0.0 in stage 3.0 (TID 4) in 163 ms on 139c0fac8954 (executor driver) (1/1)
[2026-01-11T15:48:31.844+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSchedulerImpl: Removed TaskSet 3.0, whose tasks have all completed, from pool
[2026-01-11T15:48:31.846+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.178 s
[2026-01-11T15:48:31.846+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
[2026-01-11T15:48:31.847+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO TaskSchedulerImpl: Killing all running tasks in stage 3: Stage finished
[2026-01-11T15:48:31.848+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.181560 s
[2026-01-11T15:48:31.879+0000] {subprocess.py:93} INFO - 26/01/11 15:48:31 INFO CodeGenerator: Code generated in 17.89991 ms
[2026-01-11T15:48:31.941+0000] {subprocess.py:93} INFO - +--------------------+--------+-----------------------+--------------+--------------------+--------------------+---------+--------+------+--------------------+--------+--------------------+----------------+--------+--------------------+-------+------------------+-------+-------+----------+--------------------+----------------+---------------+--------------+----------+--------+------------+------------+--------------------+--------+
[2026-01-11T15:48:31.942+0000] {subprocess.py:93} INFO - |     billing_address|currency|original_transaction_id|payment_method|            products|    shipping_address|   status|subtotal|   tax|         t_timestamp|   total|      transaction_id|transaction_type| user_id|             product|browser|              city|country| device|element_id|            event_id|      event_type|     ip_address|          page|product_id|quantity|search_query|  session_id|           timestamp| user_id|
[2026-01-11T15:48:31.943+0000] {subprocess.py:93} INFO - +--------------------+--------+-----------------------+--------------+--------------------+--------------------+---------+--------+------+--------------------+--------+--------------------+----------------+--------+--------------------+-------+------------------+-------+-------+----------+--------------------+----------------+---------------+--------------+----------+--------+------------+------------+--------------------+--------+
[2026-01-11T15:48:31.944+0000] {subprocess.py:93} INFO - |{Webstershire, TM...|     AUD|                   NULL|     apple_pay|[{books, PROD_116...|{Williamport, AZ,...|completed| 3180.69| 254.1|2026-01-11T15:45:...| 3434.79|c6b6e4ad-e7ea-4d5...|        purchase|bdd640fb|{beauty, PROD_112...|   Edge|       Taylormouth|     CF|desktop|      NULL|186109a9-4f1b-498...|     add_to_cart|   53.11.10.252|          home| PROD_1123|       2|        NULL|bb31d07f-f76|2026-01-11T15:45:...|bdd640fb|
[2026-01-11T15:48:31.945+0000] {subprocess.py:93} INFO - |{Marcusburgh, DZ,...|     CAD|                   NULL|    debit_card|[{books, PROD_111...|{East Jessica, MX...|completed| 3080.81|266.03|2026-01-11T15:45:...| 3346.84|c63ce21d-2443-495...|        purchase|7e570ddf|{electronics, PRO...|Firefox| New Savannahshire|     AF| mobile|      NULL|f4c8e393-96dd-4c8...|remove_from_cart|  15.251.51.190|       profile| PROD_1198|       5|        NULL|735444fb-e44|2026-01-11T15:45:...|7e570ddf|
[2026-01-11T15:48:31.945+0000] {subprocess.py:93} INFO - |{South Christophe...|     AUD|                   NULL|    debit_card|[{clothing, PROD_...|{Christopherside,...|completed| 2607.89|198.91|2026-01-11T15:45:...|  2806.8|badf9397-ecf2-442...|        purchase|885f6e66|{clothing, PROD_1...|   Edge|       Madisonfort|     BT| tablet|      NULL|0df407b8-2751-4b8...|     add_to_cart|  59.93.229.101|      products| PROD_1066|       3|        NULL|8cb6b0ba-925|2026-01-11T15:45:...|885f6e66|
[2026-01-11T15:48:31.946+0000] {subprocess.py:93} INFO - |{Arellanoshire, B...|     GBP|                   NULL|    debit_card|[{toys, PROD_1056...|{North Stacy, DM,...|completed| 3904.22|315.07|2026-01-11T15:45:...| 4219.29|7092d401-4367-4d5...|        purchase|bdd640fb|{beauty, PROD_115...|   Edge|         Lake Kyle|     EE| tablet|      NULL|17a52aa6-69e3-47c...|remove_from_cart|  29.237.48.138|      settings| PROD_1157|       4|        NULL|c94fff2e-bf1|2026-01-11T15:46:...|bdd640fb|
[2026-01-11T15:48:31.947+0000] {subprocess.py:93} INFO - |{Lake Maryshire, ...|     CAD|                   NULL| bank_transfer|[{food, PROD_1121...|{Lake Beth, CA, V...|completed| 2635.69|236.44|2026-01-11T15:45:...| 2872.13|23f47a55-7e0f-40b...|        purchase|ff50bde4|{toys, PROD_1074,...|   Edge|      South Daniel|     TR|desktop|      NULL|bf695686-1de8-435...|     add_to_cart| 119.170.168.66|      settings| PROD_1074|       2|        NULL|e70a7e3c-63f|2026-01-11T15:45:...|ff50bde4|
[2026-01-11T15:48:31.947+0000] {subprocess.py:93} INFO - |{Nataliemouth, KP...|     USD|   a8cfe589-9dc8-4e1...| bank_transfer|[{home, PROD_1189...|{Lake Charlestown...|completed| 3989.99|273.69|2026-01-11T15:45:...|-4263.68|27035b27-958c-493...|      chargeback|10f1bc81|{toys, PROD_1138,...| Safari|     Stephaniebury|     LC| tablet|      NULL|19147e3a-93be-4d5...|remove_from_cart|   129.3.13.194|          cart| PROD_1138|       3|        NULL|2bf6868a-0d5|2026-01-11T15:45:...|10f1bc81|
[2026-01-11T15:48:31.948+0000] {subprocess.py:93} INFO - |{Lake Zacharyberg...|     EUR|                   NULL|   credit_card|[{electronics, PR...|{Johnsonmouth, FR...|completed| 3787.27|283.95|2026-01-11T15:45:...| 4071.22|c3e1847c-8420-40d...|        purchase|b09b2a5c|{sports, PROD_111...|   Edge|      North Marcus|     KM|desktop|      NULL|bd5f4732-3c72-4ab...|     add_to_cart| 74.238.134.197|      checkout| PROD_1111|       3|        NULL|cce4c94c-036|2026-01-11T15:45:...|b09b2a5c|
[2026-01-11T15:48:31.948+0000] {subprocess.py:93} INFO - |{Reeveshaven, KR,...|     EUR|                   NULL|        paypal|[{books, PROD_107...|{Andrewport, LI, ...|   failed| 2976.03|161.14|2026-01-11T15:45:...| 3137.17|5711d5fd-30b1-467...|        purchase|451b4cf3|{toys, PROD_1020,...|   Edge|  Christopherhaven|     CU| tablet|      NULL|89a5c5bb-7009-41e...|     add_to_cart|   218.86.253.4|      products| PROD_1020|       3|        NULL|21696a07-a78|2026-01-11T15:45:...|451b4cf3|
[2026-01-11T15:48:31.950+0000] {subprocess.py:93} INFO - |{Port Patrick, BB...|     AUD|                   NULL|   credit_card|[{electronics, PR...|{Martinezport, RW...|completed|  791.12| 54.66|2026-01-11T15:45:...|  845.78|de162c17-fd06-417...|        purchase|bdd640fb|{electronics, PRO...|Firefox|     Elizabethberg|     MR|desktop|      NULL|808e67c5-7a66-4a7...|remove_from_cart| 129.199.65.179|       profile| PROD_1149|       5|        NULL|3f92d258-483|2026-01-11T15:46:...|bdd640fb|
[2026-01-11T15:48:31.950+0000] {subprocess.py:93} INFO - |{South Barbarasid...|     GBP|                   NULL|   credit_card|[{beauty, PROD_10...|{Samuelhaven, LA,...|completed| 1788.97|153.86|2026-01-11T15:45:...| 1942.83|6e89a7a8-b68d-403...|        purchase|7914c120|{food, PROD_1067,...| Safari|     Lake Alanland|     KW|desktop|      NULL|ad7eeff7-5660-476...|     add_to_cart| 139.131.193.33|      settings| PROD_1067|       2|        NULL|c53f4f7e-96b|2026-01-11T15:45:...|7914c120|
[2026-01-11T15:48:31.951+0000] {subprocess.py:93} INFO - |{Millerhaven, MR,...|     CAD|                   NULL|     apple_pay|[{clothing, PROD_...|{Deniseburgh, RO,...|completed| 1177.86| 113.5|2026-01-11T15:45:...| 1291.36|68518341-0766-499...|        purchase|7e570ddf|{home, PROD_1167,...| Safari|        North Ryan|     TL| mobile|      NULL|d3a085ec-2c1f-40d...|     add_to_cart|146.252.117.234|          cart| PROD_1167|       2|        NULL|2777a40b-cff|2026-01-11T15:45:...|7e570ddf|
[2026-01-11T15:48:31.952+0000] {subprocess.py:93} INFO - |{South Jamesland,...|     EUR|                   NULL|   credit_card|[{food, PROD_1151...|{Lake Colleentown...|completed| 3238.75|210.79|2026-01-11T15:45:...| 3449.54|5c896b2a-7edd-4c1...|        purchase|ab9099a4|{toys, PROD_1135,...| Safari|    Melissaborough|     GA|desktop|      NULL|2ad13118-2ee3-48d...|     add_to_cart|  98.19.248.136|      settings| PROD_1135|       1|        NULL|a55b8e54-c0a|2026-01-11T15:46:...|ab9099a4|
[2026-01-11T15:48:31.952+0000] {subprocess.py:93} INFO - |{Kellytown, KM, N...|     AUD|                   NULL|   credit_card|[{toys, PROD_1146...|{Port Casey, PY, ...|completed|  756.14| 72.53|2026-01-11T15:45:...|  828.67|20afaf9e-0f7c-49a...|        purchase|81f631d4|{home, PROD_1011,...| Safari|       Chaneyburgh|     CD| tablet|      NULL|54c3b22e-4c66-4a4...|     add_to_cart| 209.145.170.58|product_detail| PROD_1011|       1|        NULL|93fde248-aac|2026-01-11T15:45:...|81f631d4|
[2026-01-11T15:48:31.953+0000] {subprocess.py:93} INFO - |{East James, BZ, ...|     AUD|                   NULL| bank_transfer|[{books, PROD_109...|{Allenstad, SL, T...|completed| 6715.48|479.24|2026-01-11T15:45:...| 7194.72|5c230306-c3f9-440...|        purchase|7e570ddf|{books, PROD_1090...| Safari|      Hollandmouth|     LI| mobile|      NULL|7143dea7-e2fb-455...|remove_from_cart| 192.168.215.68|          home| PROD_1090|       3|        NULL|798e304b-756|2026-01-11T15:46:...|7e570ddf|
[2026-01-11T15:48:31.954+0000] {subprocess.py:93} INFO - |{East Robertfort,...|     USD|                   NULL|    google_pay|[{beauty, PROD_10...|{Tiffanyfort, AM,...|  pending| 3220.29|286.61|2026-01-11T15:45:...|  3506.9|03d6af3f-2c72-467...|        purchase|beb79919|{beauty, PROD_101...| Chrome|        Danielfurt|     TO| mobile|      NULL|edd753fa-3181-464...|remove_from_cart|   44.224.76.71|          cart| PROD_1016|       5|        NULL|62d539b7-e07|2026-01-11T15:45:...|beb79919|
[2026-01-11T15:48:31.954+0000] {subprocess.py:93} INFO - |{West Melissa, UY...|     GBP|                   NULL|     apple_pay|[{clothing, PROD_...|{Patrickburgh, BS...|completed| 2278.52|139.91|2026-01-11T15:45:...| 2418.43|a8be8d1f-4b1c-4df...|        purchase|b09b2a5c|{books, PROD_1148...| Safari|  New Michelemouth|     LT| tablet|      NULL|3b89a4f5-5143-456...|remove_from_cart| 70.216.246.121|          cart| PROD_1148|       4|        NULL|ed290d99-7b3|2026-01-11T15:46:...|b09b2a5c|
[2026-01-11T15:48:31.955+0000] {subprocess.py:93} INFO - |{West Melissa, UY...|     GBP|                   NULL|     apple_pay|[{clothing, PROD_...|{Patrickburgh, BS...|completed| 2278.52|139.91|2026-01-11T15:45:...| 2418.43|a8be8d1f-4b1c-4df...|        purchase|b09b2a5c|{books, PROD_1148...|Firefox|     Singletonport|     QA|desktop|      NULL|10bbc60d-07bf-43e...|remove_from_cart|    27.63.0.209|          home| PROD_1148|       4|        NULL|53238aff-e1e|2026-01-11T15:45:...|b09b2a5c|
[2026-01-11T15:48:31.957+0000] {subprocess.py:93} INFO - |{West Melissa, UY...|     GBP|                   NULL|     apple_pay|[{clothing, PROD_...|{Patrickburgh, BS...|completed| 2278.52|139.91|2026-01-11T15:45:...| 2418.43|a8be8d1f-4b1c-4df...|        purchase|b09b2a5c|{sports, PROD_116...|   Edge|      South Robert|     BG| mobile|      NULL|b2c4606b-8381-423...|     add_to_cart|   102.20.97.75|       profile| PROD_1163|       2|        NULL|18b685c5-86d|2026-01-11T15:45:...|b09b2a5c|
[2026-01-11T15:48:31.957+0000] {subprocess.py:93} INFO - |{New Wesley, BY, ...|     AUD|   9810b8c1-027d-4b4...| bank_transfer|[{books, PROD_116...|{Stephenstad, LT,...|completed|  2844.0|219.02|2026-01-11T15:45:...|-3063.02|9549e631-794c-4ef...|          refund|81f631d4|{home, PROD_1129,...| Safari|Port Joshuachester|     EG| mobile|      NULL|355b8d83-b14a-4a8...|     add_to_cart|  164.173.85.26|          help| PROD_1129|       2|        NULL|0819f509-c08|2026-01-11T15:45:...|81f631d4|
[2026-01-11T15:48:31.958+0000] {subprocess.py:93} INFO - |{North Davidburgh...|     GBP|   e74f232b-fb87-427...|    google_pay|[{food, PROD_1193...|{South Janet, GN,...|completed| 2895.31|228.22|2026-01-11T15:45:...|-3123.53|57d714f1-3192-429...|          refund|a748dbcf|{beauty, PROD_101...|Firefox|         Frankview|     NE| tablet|      NULL|5cefe17f-c956-42c...|remove_from_cart|   22.45.174.79|      settings| PROD_1018|       2|        NULL|761a8f3b-2e3|2026-01-11T15:46:...|a748dbcf|
[2026-01-11T15:48:31.959+0000] {subprocess.py:93} INFO - +--------------------+--------+-----------------------+--------------+--------------------+--------------------+---------+--------+------+--------------------+--------+--------------------+----------------+--------+--------------------+-------+------------------+-------+-------+----------+--------------------+----------------+---------------+--------------+----------+--------+------------+------------+--------------------+--------+
[2026-01-11T15:48:31.959+0000] {subprocess.py:93} INFO - only showing top 20 rows
[2026-01-11T15:48:31.960+0000] {subprocess.py:93} INFO - 
[2026-01-11T15:48:31.961+0000] {subprocess.py:93} INFO - None
[2026-01-11T15:48:32.253+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(user_id),IsNotNull(products)
[2026-01-11T15:48:32.254+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(user_id#21),(size(products#12, true) > 0),isnotnull(products#12)
[2026-01-11T15:48:32.255+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(user_id),IsNotNull(product_id)
[2026-01-11T15:48:32.256+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(user_id#58),isnotnull(product_id#53)
[2026-01-11T15:48:32.296+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 6.913415 ms
[2026-01-11T15:48:32.299+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_9 stored as values in memory (estimated size 199.1 KiB, free 432.1 MiB)
[2026-01-11T15:48:32.309+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Removed broadcast_8_piece0 on 139c0fac8954:41559 in memory (size: 15.4 KiB, free: 434.0 MiB)
[2026-01-11T15:48:32.312+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 432.2 MiB)
[2026-01-11T15:48:32.313+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Added broadcast_9_piece0 in memory on 139c0fac8954:41559 (size: 34.2 KiB, free: 434.0 MiB)
[2026-01-11T15:48:32.314+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Created broadcast 9 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2026-01-11T15:48:32.315+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2026-01-11T15:48:32.330+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Starting job: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2026-01-11T15:48:32.332+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Got job 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) with 1 output partitions
[2026-01-11T15:48:32.332+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Final stage: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264)
[2026-01-11T15:48:32.333+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Parents of final stage: List()
[2026-01-11T15:48:32.333+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Missing parents: List()
[2026-01-11T15:48:32.334+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[19] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264), which has no missing parents
[2026-01-11T15:48:32.335+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_10 stored as values in memory (estimated size 15.6 KiB, free 432.2 MiB)
[2026-01-11T15:48:32.341+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.4 KiB, free 432.1 MiB)
[2026-01-11T15:48:32.342+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Added broadcast_10_piece0 in memory on 139c0fac8954:41559 (size: 7.4 KiB, free: 434.0 MiB)
[2026-01-11T15:48:32.343+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Created broadcast 10 from broadcast at DAGScheduler.scala:1580
[2026-01-11T15:48:32.344+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[19] at $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) (first 15 tasks are for partitions Vector(0))
[2026-01-11T15:48:32.345+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSchedulerImpl: Adding task set 4.0 with 1 tasks resource profile 0
[2026-01-11T15:48:32.345+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSetManager: Starting task 0.0 in stage 4.0 (TID 5) (139c0fac8954, executor driver, partition 0, PROCESS_LOCAL, 8244 bytes)
[2026-01-11T15:48:32.346+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO Executor: Running task 0.0 in stage 4.0 (TID 5)
[2026-01-11T15:48:32.358+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 6.595855 ms
[2026-01-11T15:48:32.359+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/user_events_1768146431.4385798.json, range: 0-1917087, partition values: [empty row]
[2026-01-11T15:48:32.367+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 5.552351 ms
[2026-01-11T15:48:32.373+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 3.446235 ms
[2026-01-11T15:48:32.379+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 4.145754 ms
[2026-01-11T15:48:32.488+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO Executor: Finished task 0.0 in stage 4.0 (TID 5). 32157 bytes result sent to driver
[2026-01-11T15:48:32.489+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSetManager: Finished task 0.0 in stage 4.0 (TID 5) in 144 ms on 139c0fac8954 (executor driver) (1/1)
[2026-01-11T15:48:32.490+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSchedulerImpl: Removed TaskSet 4.0, whose tasks have all completed, from pool
[2026-01-11T15:48:32.491+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: ResultStage 4 ($anonfun$withThreadLocalCaptured$1 at FutureTask.java:264) finished in 0.157 s
[2026-01-11T15:48:32.492+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Job 4 is finished. Cancelling potential speculative or zombie tasks for this job
[2026-01-11T15:48:32.492+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSchedulerImpl: Killing all running tasks in stage 4: Stage finished
[2026-01-11T15:48:32.493+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Job 4 finished: $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264, took 0.161995 s
[2026-01-11T15:48:32.501+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 4.784285 ms
[2026-01-11T15:48:32.509+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_11 stored as values in memory (estimated size 1088.0 KiB, free 431.1 MiB)
[2026-01-11T15:48:32.518+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Removed broadcast_10_piece0 on 139c0fac8954:41559 in memory (size: 7.4 KiB, free: 434.0 MiB)
[2026-01-11T15:48:32.519+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 54.5 KiB, free 431.0 MiB)
[2026-01-11T15:48:32.519+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Added broadcast_11_piece0 in memory on 139c0fac8954:41559 (size: 54.5 KiB, free: 434.0 MiB)
[2026-01-11T15:48:32.520+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Created broadcast 11 from $anonfun$withThreadLocalCaptured$1 at FutureTask.java:264
[2026-01-11T15:48:32.534+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceStrategy: Pushed Filters: IsNotNull(user_id),IsNotNull(products)
[2026-01-11T15:48:32.536+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceStrategy: Post-Scan Filters: isnotnull(user_id#21),(size(products#12, true) > 0),isnotnull(products#12)
[2026-01-11T15:48:32.689+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2026-01-11T15:48:32.690+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2026-01-11T15:48:32.691+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2026-01-11T15:48:32.834+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO CodeGenerator: Code generated in 30.629351 ms
[2026-01-11T15:48:32.839+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_12 stored as values in memory (estimated size 199.1 KiB, free 430.9 MiB)
[2026-01-11T15:48:32.851+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 34.2 KiB, free 430.8 MiB)
[2026-01-11T15:48:32.852+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Added broadcast_12_piece0 in memory on 139c0fac8954:41559 (size: 34.2 KiB, free: 433.9 MiB)
[2026-01-11T15:48:32.854+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Created broadcast 12 from csv at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:32.855+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO FileSourceScanExec: Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
[2026-01-11T15:48:32.867+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Starting job: csv at NativeMethodAccessorImpl.java:0
[2026-01-11T15:48:32.869+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Got job 5 (csv at NativeMethodAccessorImpl.java:0) with 2 output partitions
[2026-01-11T15:48:32.870+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Final stage: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0)
[2026-01-11T15:48:32.871+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Parents of final stage: List()
[2026-01-11T15:48:32.872+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Missing parents: List()
[2026-01-11T15:48:32.873+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0), which has no missing parents
[2026-01-11T15:48:32.918+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_13 stored as values in memory (estimated size 232.6 KiB, free 430.6 MiB)
[2026-01-11T15:48:32.920+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 82.4 KiB, free 430.5 MiB)
[2026-01-11T15:48:32.921+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO BlockManagerInfo: Added broadcast_13_piece0 in memory on 139c0fac8954:41559 (size: 82.4 KiB, free: 433.8 MiB)
[2026-01-11T15:48:32.923+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1580
[2026-01-11T15:48:32.925+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO DAGScheduler: Submitting 2 missing tasks from ResultStage 5 (MapPartitionsRDD[23] at csv at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))
[2026-01-11T15:48:32.925+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSchedulerImpl: Adding task set 5.0 with 2 tasks resource profile 0
[2026-01-11T15:48:32.927+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSetManager: Starting task 0.0 in stage 5.0 (TID 6) (139c0fac8954, executor driver, partition 0, PROCESS_LOCAL, 8251 bytes)
[2026-01-11T15:48:32.928+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO TaskSetManager: Starting task 1.0 in stage 5.0 (TID 7) (139c0fac8954, executor driver, partition 1, PROCESS_LOCAL, 8251 bytes)
[2026-01-11T15:48:32.929+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO Executor: Running task 1.0 in stage 5.0 (TID 7)
[2026-01-11T15:48:32.930+0000] {subprocess.py:93} INFO - 26/01/11 15:48:32 INFO Executor: Running task 0.0 in stage 5.0 (TID 6)
[2026-01-11T15:48:33.002+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO CodeGenerator: Code generated in 25.590065 ms
[2026-01-11T15:48:33.005+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2026-01-11T15:48:33.005+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2026-01-11T15:48:33.006+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2026-01-11T15:48:33.007+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/transaction_events_1768146431.4381304.json, range: 4194304-5332234, partition values: [empty row]
[2026-01-11T15:48:33.009+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileOutputCommitter: File Output Committer Algorithm version is 1
[2026-01-11T15:48:33.010+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false
[2026-01-11T15:48:33.010+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter
[2026-01-11T15:48:33.023+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO CodeGenerator: Code generated in 14.659418 ms
[2026-01-11T15:48:33.032+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO CodeGenerator: Code generated in 4.991821 ms
[2026-01-11T15:48:33.218+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileScanRDD: Reading File path: file:///opt/spark-data/landing/transaction_events_1768146431.4381304.json, range: 0-4194304, partition values: [empty row]
[2026-01-11T15:48:33.453+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileOutputCommitter: Saved output of task 'attempt_202601111548322844094455695198795_0005_m_000001_7' to file:/opt/spark-data/gold/advertising/_temporary/0/task_202601111548322844094455695198795_0005_m_000001
[2026-01-11T15:48:33.454+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO SparkHadoopMapRedUtil: attempt_202601111548322844094455695198795_0005_m_000001_7: Committed. Elapsed time: 18 ms.
[2026-01-11T15:48:33.460+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO Executor: Finished task 1.0 in stage 5.0 (TID 7). 2893 bytes result sent to driver
[2026-01-11T15:48:33.461+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO TaskSetManager: Finished task 1.0 in stage 5.0 (TID 7) in 534 ms on 139c0fac8954 (executor driver) (1/2)
[2026-01-11T15:48:33.716+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileOutputCommitter: Saved output of task 'attempt_202601111548322844094455695198795_0005_m_000000_6' to file:/opt/spark-data/gold/advertising/_temporary/0/task_202601111548322844094455695198795_0005_m_000000
[2026-01-11T15:48:33.717+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO SparkHadoopMapRedUtil: attempt_202601111548322844094455695198795_0005_m_000000_6: Committed. Elapsed time: 51 ms.
[2026-01-11T15:48:33.719+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO Executor: Finished task 0.0 in stage 5.0 (TID 6). 2893 bytes result sent to driver
[2026-01-11T15:48:33.720+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO TaskSetManager: Finished task 0.0 in stage 5.0 (TID 6) in 794 ms on 139c0fac8954 (executor driver) (2/2)
[2026-01-11T15:48:33.720+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO TaskSchedulerImpl: Removed TaskSet 5.0, whose tasks have all completed, from pool
[2026-01-11T15:48:33.721+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO DAGScheduler: ResultStage 5 (csv at NativeMethodAccessorImpl.java:0) finished in 0.848 s
[2026-01-11T15:48:33.722+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO DAGScheduler: Job 5 is finished. Cancelling potential speculative or zombie tasks for this job
[2026-01-11T15:48:33.722+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO TaskSchedulerImpl: Killing all running tasks in stage 5: Stage finished
[2026-01-11T15:48:33.724+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO DAGScheduler: Job 5 finished: csv at NativeMethodAccessorImpl.java:0, took 0.854245 s
[2026-01-11T15:48:33.725+0000] {subprocess.py:93} INFO - 26/01/11 15:48:33 INFO FileFormatWriter: Start to commit write Job 7a50c506-6652-473a-a480-cdb4562b3cce.
[2026-01-11T15:48:34.091+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO FileFormatWriter: Write Job 7a50c506-6652-473a-a480-cdb4562b3cce committed. Elapsed time: 366 ms.
[2026-01-11T15:48:34.095+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO FileFormatWriter: Finished processing stats for write job 7a50c506-6652-473a-a480-cdb4562b3cce.
[2026-01-11T15:48:34.378+0000] {subprocess.py:93} INFO - Traceback (most recent call last):
[2026-01-11T15:48:34.380+0000] {subprocess.py:93} INFO -   File "/opt/spark-jobs/etl_job.py", line 157, in <module>
[2026-01-11T15:48:34.389+0000] {subprocess.py:93} INFO -     run_etl(spark,'/opt/spark-data/landing', '/opt/spark-data/gold')
[2026-01-11T15:48:34.390+0000] {subprocess.py:93} INFO -   File "/opt/spark-jobs/etl_job.py", line 144, in run_etl
[2026-01-11T15:48:34.395+0000] {subprocess.py:93} INFO -     transaction_analytics_gold(spark, df_topic_transaction, output_path)
[2026-01-11T15:48:34.396+0000] {subprocess.py:93} INFO -   File "/opt/spark-jobs/etl_job.py", line 113, in transaction_analytics_gold
[2026-01-11T15:48:34.401+0000] {subprocess.py:93} INFO -     df_analytics = spark.sql(analytics_query)
[2026-01-11T15:48:34.402+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/sql/session.py", line 1631, in sql
[2026-01-11T15:48:34.402+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py", line 1322, in __call__
[2026-01-11T15:48:34.403+0000] {subprocess.py:93} INFO -   File "/opt/spark/python/lib/pyspark.zip/pyspark/errors/exceptions/captured.py", line 185, in deco
[2026-01-11T15:48:34.409+0000] {subprocess.py:93} INFO - pyspark.errors.exceptions.captured.AnalysisException: [UNRESOLVED_COLUMN.WITH_SUGGESTION] A column or function parameter with name `t_timestamp` cannot be resolved. Did you mean one of the following? [`timestamp`, `total`, `status`, `subtotal`, `tax`].; line 4 pos 12;
[2026-01-11T15:48:34.410+0000] {subprocess.py:93} INFO - 'Project [transaction_id#19, 't_timestamp, shipping_address#13.city AS city#431, total#18, sum(total#18) windowspecdefinition(transaction_id#19, 't_timestamp ASC NULLS FIRST, specifiedwindowframe(RangeFrame, unboundedpreceding$(), currentrow$())) AS running_total_spent#429, dense_rank(total#18) windowspecdefinition(transaction_id#19, total#18 DESC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS purchase_rank_by_price#430]
[2026-01-11T15:48:34.411+0000] {subprocess.py:93} INFO - +- SubqueryAlias view_transactions
[2026-01-11T15:48:34.412+0000] {subprocess.py:93} INFO -    +- View (`view_transactions`, [billing_address#8,currency#9,original_transaction_id#10,payment_method#11,products#12,shipping_address#13,status#14,subtotal#15,tax#16,timestamp#17,total#18,transaction_id#19,transaction_type#20,user_id#21])
[2026-01-11T15:48:34.413+0000] {subprocess.py:93} INFO -       +- Relation [billing_address#8,currency#9,original_transaction_id#10,payment_method#11,products#12,shipping_address#13,status#14,subtotal#15,tax#16,timestamp#17,total#18,transaction_id#19,transaction_type#20,user_id#21] json
[2026-01-11T15:48:34.414+0000] {subprocess.py:93} INFO - 
[2026-01-11T15:48:34.462+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO SparkContext: Invoking stop() from shutdown hook
[2026-01-11T15:48:34.463+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO SparkContext: SparkContext is stopping with exitCode 0.
[2026-01-11T15:48:34.476+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO SparkUI: Stopped Spark web UI at http://139c0fac8954:4040
[2026-01-11T15:48:34.488+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
[2026-01-11T15:48:34.506+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO MemoryStore: MemoryStore cleared
[2026-01-11T15:48:34.507+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO BlockManager: BlockManager stopped
[2026-01-11T15:48:34.511+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO BlockManagerMaster: BlockManagerMaster stopped
[2026-01-11T15:48:34.514+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
[2026-01-11T15:48:34.527+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO SparkContext: Successfully stopped SparkContext
[2026-01-11T15:48:34.528+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO ShutdownHookManager: Shutdown hook called
[2026-01-11T15:48:34.529+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-d4376739-1409-4f89-90bf-4bc462093075
[2026-01-11T15:48:34.533+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-d4376739-1409-4f89-90bf-4bc462093075/pyspark-9fd7501c-498b-40dd-a89b-00dc9005fbfe
[2026-01-11T15:48:34.536+0000] {subprocess.py:93} INFO - 26/01/11 15:48:34 INFO ShutdownHookManager: Deleting directory /tmp/spark-c4bf5489-8811-47a6-bdb4-6628cb76cf9f
[2026-01-11T15:48:34.629+0000] {subprocess.py:97} INFO - Command exited with return code 1
[2026-01-11T15:48:34.641+0000] {taskinstance.py:2698} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/models/taskinstance.py", line 433, in _execute_task
    result = execute_callable(context=context, **execute_callable_kwargs)
  File "/home/airflow/.local/lib/python3.10/site-packages/airflow/operators/bash.py", line 212, in execute
    raise AirflowException(
airflow.exceptions.AirflowException: Bash command failed. The command returned a non-zero exit code 1.
[2026-01-11T15:48:34.645+0000] {taskinstance.py:1138} INFO - Marking task as FAILED. dag_id=streamflow_main, task_id=Spark_Submit, execution_date=20260111T154708, start_date=20260111T154817, end_date=20260111T154834
[2026-01-11T15:48:34.662+0000] {standard_task_runner.py:107} ERROR - Failed to execute job 4 for task Spark_Submit (Bash command failed. The command returned a non-zero exit code 1.; 342)
[2026-01-11T15:48:34.672+0000] {local_task_job_runner.py:234} INFO - Task exited with return code 1
[2026-01-11T15:48:34.695+0000] {taskinstance.py:3280} INFO - 0 downstream tasks scheduled from follow-on schedule check
